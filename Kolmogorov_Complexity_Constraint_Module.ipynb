{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxXAnx1xY9oB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e564ff9-ff99-4171-da60-0bfbdcc1ad31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "  Weights: [0.1952489  0.19654665 0.19778107 0.20577626 0.20464711]\n",
            "  Objective value: 0.890859\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 2/100\n",
            "  Weights: [0.19005822 0.19271724 0.19539829 0.21212774 0.2096985 ]\n",
            "  Objective value: 0.881640\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 3/100\n",
            "  Weights: [0.184393   0.18847639 0.19284288 0.21910438 0.21518335]\n",
            "  Objective value: 0.871661\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 4/100\n",
            "  Weights: [0.17821669 0.18378647 0.19010619 0.22675891 0.22113174]\n",
            "  Objective value: 0.860881\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 5/100\n",
            "  Weights: [0.17149138 0.17860766 0.1871799  0.23514666 0.22757441]\n",
            "  Objective value: 0.849261\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 6/100\n",
            "  Weights: [0.16417802 0.17289811 0.1840561  0.2443253  0.23454247]\n",
            "  Objective value: 0.836764\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 7/100\n",
            "  Weights: [0.15623678 0.16661415 0.18072756 0.25435447 0.24206704]\n",
            "  Objective value: 0.823361\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 8/100\n",
            "  Weights: [0.14762747 0.15971058 0.1771879  0.26529526 0.25017879]\n",
            "  Objective value: 0.809025\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 9/100\n",
            "  Weights: [0.13831004 0.15214107 0.17343186 0.27720962 0.25890741]\n",
            "  Objective value: 0.793738\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 10/100\n",
            "  Weights: [0.1282452  0.14385866 0.16945551 0.29015957 0.26828105]\n",
            "  Objective value: 0.777490\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 11/100\n",
            "  Weights: [0.11739518 0.13481634 0.16525662 0.30420628 0.27832557]\n",
            "  Objective value: 0.760282\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 12/100\n",
            "  Weights: [0.10572447 0.12496784 0.16083488 0.31940898 0.28906382]\n",
            "  Objective value: 0.742128\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 13/100\n",
            "  Weights: [0.09320086 0.11426841 0.15619226 0.33582371 0.30051476]\n",
            "  Objective value: 0.723054\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 14/100\n",
            "  Weights: [0.07979634 0.10267584 0.15133331 0.35350194 0.31269257]\n",
            "  Objective value: 0.703102\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 15/100\n",
            "  Weights: [0.06548828 0.09015152 0.14626544 0.37248905 0.32560571]\n",
            "  Objective value: 0.682330\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 16/100\n",
            "  Weights: [0.05026052 0.0766616  0.14099923 0.39282266 0.33925599]\n",
            "  Objective value: 0.660813\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 17/100\n",
            "  Weights: [0.03410455 0.06217827 0.13554865 0.41453098 0.35363756]\n",
            "  Objective value: 0.638645\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 18/100\n",
            "  Weights: [0.01702061 0.046681   0.12993125 0.43763104 0.36873611]\n",
            "  Objective value: 0.615936\n",
            "  Penalty value: 0.060000\n",
            "  Sparsity (non-zero weights): 5\n",
            "\n",
            "Epoch 19/100\n",
            "  Weights: [0.         0.03012826 0.12404655 0.46167408 0.38415111]\n",
            "  Objective value: 0.583286\n",
            "  Penalty value: 0.050000\n",
            "  Sparsity (non-zero weights): 4\n",
            "\n",
            "Epoch 20/100\n",
            "  Weights: [0.         0.01233758 0.11595718 0.47852251 0.39318273]\n",
            "  Objective value: 0.568968\n",
            "  Penalty value: 0.050000\n",
            "  Sparsity (non-zero weights): 4\n",
            "\n",
            "Epoch 21/100\n",
            "  Weights: [0.         0.         0.10688687 0.4930956  0.40001753]\n",
            "  Objective value: 0.548091\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 22/100\n",
            "  Weights: [0.         0.         0.09628499 0.5018479  0.40186711]\n",
            "  Objective value: 0.544674\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 23/100\n",
            "  Weights: [0.         0.         0.08543809 0.51088168 0.40368023]\n",
            "  Objective value: 0.541320\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 24/100\n",
            "  Weights: [0.         0.         0.07434507 0.52020238 0.40545255]\n",
            "  Objective value: 0.538038\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 25/100\n",
            "  Weights: [0.         0.         0.06300508 0.52981531 0.40717961]\n",
            "  Objective value: 0.534836\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 26/100\n",
            "  Weights: [0.         0.         0.05141757 0.53972562 0.40885681]\n",
            "  Objective value: 0.531723\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 27/100\n",
            "  Weights: [0.         0.         0.03958232 0.54993831 0.41047937]\n",
            "  Objective value: 0.528707\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 28/100\n",
            "  Weights: [0.         0.         0.02749941 0.5604582  0.4120424 ]\n",
            "  Objective value: 0.525797\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 29/100\n",
            "  Weights: [0.         0.         0.01516923 0.5712899  0.41354087]\n",
            "  Objective value: 0.523001\n",
            "  Penalty value: 0.040000\n",
            "  Sparsity (non-zero weights): 3\n",
            "\n",
            "Epoch 30/100\n",
            "  Weights: [0.         0.         0.         0.58395175 0.41604825]\n",
            "  Objective value: 0.510097\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 31/100\n",
            "  Weights: [0.         0.         0.         0.58789139 0.41210861]\n",
            "  Objective value: 0.508637\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 32/100\n",
            "  Weights: [0.         0.         0.         0.59191354 0.40808646]\n",
            "  Objective value: 0.507157\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 33/100\n",
            "  Weights: [0.         0.         0.         0.59601981 0.40398019]\n",
            "  Objective value: 0.505655\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 34/100\n",
            "  Weights: [0.         0.         0.         0.60021186 0.39978814]\n",
            "  Objective value: 0.504132\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 35/100\n",
            "  Weights: [0.         0.         0.         0.60449138 0.39550862]\n",
            "  Objective value: 0.502588\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 36/100\n",
            "  Weights: [0.         0.         0.         0.60886008 0.39113992]\n",
            "  Objective value: 0.501023\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 37/100\n",
            "  Weights: [0.        0.        0.        0.6133197 0.3866803]\n",
            "  Objective value: 0.499437\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 38/100\n",
            "  Weights: [0.         0.         0.         0.61787201 0.38212799]\n",
            "  Objective value: 0.497831\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 39/100\n",
            "  Weights: [0.         0.         0.         0.62251881 0.37748119]\n",
            "  Objective value: 0.496204\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 40/100\n",
            "  Weights: [0.         0.         0.         0.62726193 0.37273807]\n",
            "  Objective value: 0.494556\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 41/100\n",
            "  Weights: [0.         0.         0.         0.63210322 0.36789678]\n",
            "  Objective value: 0.492888\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 42/100\n",
            "  Weights: [0.         0.         0.         0.63704458 0.36295542]\n",
            "  Objective value: 0.491199\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 43/100\n",
            "  Weights: [0.         0.         0.         0.64208793 0.35791207]\n",
            "  Objective value: 0.489491\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 44/100\n",
            "  Weights: [0.        0.        0.        0.6472352 0.3527648]\n",
            "  Objective value: 0.487763\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 45/100\n",
            "  Weights: [0.         0.         0.         0.65248839 0.34751161]\n",
            "  Objective value: 0.486016\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 46/100\n",
            "  Weights: [0.        0.        0.        0.6578495 0.3421505]\n",
            "  Objective value: 0.484250\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 47/100\n",
            "  Weights: [0.         0.         0.         0.66332057 0.33667943]\n",
            "  Objective value: 0.482465\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 48/100\n",
            "  Weights: [0.         0.         0.         0.66890367 0.33109633]\n",
            "  Objective value: 0.480662\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 49/100\n",
            "  Weights: [0.        0.        0.        0.6746009 0.3253991]\n",
            "  Objective value: 0.478841\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 50/100\n",
            "  Weights: [0.         0.         0.         0.68041441 0.31958559]\n",
            "  Objective value: 0.477002\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 51/100\n",
            "  Weights: [0.         0.         0.         0.68634635 0.31365365]\n",
            "  Objective value: 0.475147\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 52/100\n",
            "  Weights: [0.         0.         0.         0.69239892 0.30760108]\n",
            "  Objective value: 0.473276\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 53/100\n",
            "  Weights: [0.         0.         0.         0.69857436 0.30142564]\n",
            "  Objective value: 0.471389\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 54/100\n",
            "  Weights: [0.         0.         0.         0.70487491 0.29512509]\n",
            "  Objective value: 0.469487\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 55/100\n",
            "  Weights: [0.         0.         0.         0.71130287 0.28869713]\n",
            "  Objective value: 0.467570\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 56/100\n",
            "  Weights: [0.         0.         0.         0.71786056 0.28213944]\n",
            "  Objective value: 0.465641\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 57/100\n",
            "  Weights: [0.         0.         0.         0.72455034 0.27544966]\n",
            "  Objective value: 0.463698\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 58/100\n",
            "  Weights: [0.        0.        0.        0.7313746 0.2686254]\n",
            "  Objective value: 0.461745\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 59/100\n",
            "  Weights: [0.         0.         0.         0.73833575 0.26166425]\n",
            "  Objective value: 0.459780\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 60/100\n",
            "  Weights: [0.         0.         0.         0.74543623 0.25456377]\n",
            "  Objective value: 0.457805\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 61/100\n",
            "  Weights: [0.         0.         0.         0.75267853 0.24732147]\n",
            "  Objective value: 0.455822\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 62/100\n",
            "  Weights: [0.         0.         0.         0.76006517 0.23993483]\n",
            "  Objective value: 0.453832\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 63/100\n",
            "  Weights: [0.         0.         0.         0.76759867 0.23240133]\n",
            "  Objective value: 0.451835\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 64/100\n",
            "  Weights: [0.         0.         0.         0.77528161 0.22471839]\n",
            "  Objective value: 0.449833\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 65/100\n",
            "  Weights: [0.        0.        0.        0.7831166 0.2168834]\n",
            "  Objective value: 0.447827\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 66/100\n",
            "  Weights: [0.         0.         0.         0.79110627 0.20889373]\n",
            "  Objective value: 0.445820\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 67/100\n",
            "  Weights: [0.         0.         0.         0.79925327 0.20074673]\n",
            "  Objective value: 0.443812\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 68/100\n",
            "  Weights: [0.         0.         0.         0.80756031 0.19243969]\n",
            "  Objective value: 0.441804\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 69/100\n",
            "  Weights: [0.         0.         0.         0.81603009 0.18396991]\n",
            "  Objective value: 0.439800\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 70/100\n",
            "  Weights: [0.         0.         0.         0.82466537 0.17533463]\n",
            "  Objective value: 0.437800\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 71/100\n",
            "  Weights: [0.         0.         0.         0.83346893 0.16653107]\n",
            "  Objective value: 0.435807\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 72/100\n",
            "  Weights: [0.         0.         0.         0.84244356 0.15755644]\n",
            "  Objective value: 0.433822\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 73/100\n",
            "  Weights: [0.        0.        0.        0.8515921 0.1484079]\n",
            "  Objective value: 0.431848\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 74/100\n",
            "  Weights: [0.         0.         0.         0.86091741 0.13908259]\n",
            "  Objective value: 0.429887\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 75/100\n",
            "  Weights: [0.         0.         0.         0.87042236 0.12957764]\n",
            "  Objective value: 0.427941\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 76/100\n",
            "  Weights: [0.         0.         0.         0.88010986 0.11989014]\n",
            "  Objective value: 0.426013\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 77/100\n",
            "  Weights: [0.         0.         0.         0.88998285 0.11001715]\n",
            "  Objective value: 0.424105\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 78/100\n",
            "  Weights: [0.         0.         0.         0.90004428 0.09995572]\n",
            "  Objective value: 0.422220\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 79/100\n",
            "  Weights: [0.         0.         0.         0.91029711 0.08970289]\n",
            "  Objective value: 0.420361\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 80/100\n",
            "  Weights: [0.         0.         0.         0.92074436 0.07925564]\n",
            "  Objective value: 0.418531\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 81/100\n",
            "  Weights: [0.         0.         0.         0.93138903 0.06861097]\n",
            "  Objective value: 0.416733\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 82/100\n",
            "  Weights: [0.         0.         0.         0.94223417 0.05776583]\n",
            "  Objective value: 0.414970\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 83/100\n",
            "  Weights: [0.         0.         0.         0.95328282 0.04671718]\n",
            "  Objective value: 0.413245\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 84/100\n",
            "  Weights: [0.         0.         0.         0.96453806 0.03546194]\n",
            "  Objective value: 0.411563\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 85/100\n",
            "  Weights: [0.         0.         0.         0.97600297 0.02399703]\n",
            "  Objective value: 0.409927\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 86/100\n",
            "  Weights: [0.         0.         0.         0.98768065 0.01231935]\n",
            "  Objective value: 0.408340\n",
            "  Penalty value: 0.030000\n",
            "  Sparsity (non-zero weights): 2\n",
            "\n",
            "Epoch 87/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 88/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 89/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 90/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 91/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 92/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 93/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 94/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 95/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 96/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 97/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 98/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 99/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "Epoch 100/100\n",
            "  Weights: [0. 0. 0. 1. 0.]\n",
            "  Objective value: 0.396753\n",
            "  Penalty value: 0.020000\n",
            "  Sparsity (non-zero weights): 1\n",
            "\n",
            "✅ Log saved to kc_portfolio_verbose_log.txt\n",
            "\n",
            "✅ Final optimized weights: [0. 0. 0. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def kc_penalty(w, gamma=1e-2, eta=1e-2):\n",
        "    \"\"\"Approximate Kolmogorov complexity penalty as a combination of L0 and L1 penalties.\"\"\"\n",
        "    l0 = np.count_nonzero(w)\n",
        "    l1 = np.sum(np.abs(w))\n",
        "    return gamma * l0 + eta * l1\n",
        "\n",
        "def objective(w, Sigma, mu, lam, gamma, eta):\n",
        "    \"\"\"Full objective function: risk, return, and KC penalty.\"\"\"\n",
        "    risk = w.T @ Sigma @ w\n",
        "    ret = w.T @ mu\n",
        "    penalty = kc_penalty(w, gamma, eta)\n",
        "    return risk - lam * ret + penalty\n",
        "\n",
        "def grad_objective(w, Sigma, mu, lam, eta):\n",
        "    \"\"\"Gradient of the objective function.\"\"\"\n",
        "    grad_risk = 2 * Sigma @ w\n",
        "    grad_ret = lam * mu\n",
        "    grad_l1 = eta * np.sign(w)\n",
        "    return grad_risk - grad_ret + grad_l1\n",
        "\n",
        "def optimize_weights(Sigma, mu, lam=0.1, gamma=1e-2, eta=1e-2, lr=1e-2, epochs=500, verbose=True):\n",
        "    \"\"\"Main optimization loop with verbose output and KC penalty regularization.\"\"\"\n",
        "    n_assets = len(mu)\n",
        "    w = np.ones(n_assets) / n_assets  # Start with equal weights\n",
        "\n",
        "    log_lines = []\n",
        "    log_lines.append(\"==== Kolmogorov Complexity Constraint Portfolio Optimization ====\\n\")\n",
        "    log_lines.append(f\"Initial weights: {w}\\n\")\n",
        "    log_lines.append(f\"lambda: {lam}, gamma: {gamma}, eta: {eta}, lr: {lr}, epochs: {epochs}\\n\\n\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        grad = grad_objective(w, Sigma, mu, lam, eta)\n",
        "        w -= lr * grad\n",
        "\n",
        "        # Apply approximate L0 penalty (threshold small values to zero)\n",
        "        w[np.abs(w) < gamma] = 0\n",
        "\n",
        "        # Optional projection to ensure weights are non-negative and sum to one\n",
        "        w = np.maximum(w, 0)\n",
        "        if np.sum(w) > 0:\n",
        "            w /= np.sum(w)\n",
        "\n",
        "        # Calculate current objective value\n",
        "        obj_val = objective(w, Sigma, mu, lam, gamma, eta)\n",
        "        penalty_val = kc_penalty(w, gamma, eta)\n",
        "        sparsity = np.count_nonzero(w)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch}/{epochs}\")\n",
        "            print(f\"  Weights: {w}\")\n",
        "            print(f\"  Objective value: {obj_val:.6f}\")\n",
        "            print(f\"  Penalty value: {penalty_val:.6f}\")\n",
        "            print(f\"  Sparsity (non-zero weights): {sparsity}\\n\")\n",
        "\n",
        "        log_lines.append(f\"Epoch {epoch}: Weights: {w.tolist()}, Objective: {obj_val:.6f}, Penalty: {penalty_val:.6f}, Sparsity: {sparsity}\\n\")\n",
        "\n",
        "    log_lines.append(\"\\n==== Optimization Completed ====\\n\")\n",
        "    log_lines.append(f\"Final weights: {w}\\n\")\n",
        "    log_lines.append(f\"Final sparsity (non-zero): {np.count_nonzero(w)}\\n\")\n",
        "    log_lines.append(\"============================================================\\n\")\n",
        "\n",
        "    # Write log to text file\n",
        "    with open(\"kc_portfolio_verbose_log.txt\", \"w\") as f:\n",
        "        f.writelines(log_lines)\n",
        "\n",
        "    print(\"✅ Log saved to kc_portfolio_verbose_log.txt\")\n",
        "\n",
        "    return w\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "\n",
        "    n_assets = 5\n",
        "    Sigma = np.random.rand(n_assets, n_assets)\n",
        "    Sigma = Sigma @ Sigma.T  # Make it symmetric and positive semi-definite\n",
        "    mu = np.random.rand(n_assets)\n",
        "\n",
        "    optimized_weights = optimize_weights(\n",
        "        Sigma,\n",
        "        mu,\n",
        "        lam=0.5,\n",
        "        gamma=0.01,\n",
        "        eta=0.01,\n",
        "        lr=0.01,\n",
        "        epochs=100,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    print(\"\\n✅ Final optimized weights:\", optimized_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Helper functions (reuse from main code)\n",
        "def kc_penalty(w, gamma=1e-2, eta=1e-2):\n",
        "    l0 = np.count_nonzero(w)\n",
        "    l1 = np.sum(np.abs(w))\n",
        "    return gamma * l0 + eta * l1\n",
        "\n",
        "def objective(w, Sigma, mu, lam, gamma, eta):\n",
        "    risk = w.T @ Sigma @ w\n",
        "    ret = w.T @ mu\n",
        "    penalty = kc_penalty(w, gamma, eta)\n",
        "    return risk - lam * ret + penalty\n",
        "\n",
        "def grad_objective(w, Sigma, mu, lam, eta):\n",
        "    grad_risk = 2 * Sigma @ w\n",
        "    grad_ret = lam * mu\n",
        "    grad_l1 = eta * np.sign(w)\n",
        "    return grad_risk - grad_ret + grad_l1\n",
        "\n",
        "def optimize_weights(Sigma, mu, lam, gamma, eta, lr=1e-2, epochs=300, verbose=False):\n",
        "    n_assets = len(mu)\n",
        "    w = np.ones(n_assets) / n_assets\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        grad = grad_objective(w, Sigma, mu, lam, eta)\n",
        "        w -= lr * grad\n",
        "        w[np.abs(w) < gamma] = 0\n",
        "        w = np.maximum(w, 0)\n",
        "        if np.sum(w) > 0:\n",
        "            w /= np.sum(w)\n",
        "    return w\n",
        "\n",
        "# Create one large log string\n",
        "master_log = \"\"\n",
        "\n",
        "# Hyperparameter ranges\n",
        "gammas = [0.001, 0.01, 0.05, 0.1]\n",
        "etas = [0.001, 0.01, 0.05, 0.1]\n",
        "lambdas = [0.1, 0.5, 1.0, 5.0]\n",
        "\n",
        "# Number of assets\n",
        "n_assets_list = [5, 20, 50, 100]\n",
        "\n",
        "# Loop over all configurations\n",
        "for n_assets in n_assets_list:\n",
        "    np.random.seed(42)\n",
        "    Sigma = np.random.rand(n_assets, n_assets)\n",
        "    Sigma = Sigma @ Sigma.T + 1e-3 * np.eye(n_assets)  # ensure positive definiteness\n",
        "    mu = np.random.rand(n_assets)\n",
        "\n",
        "    for gamma in gammas:\n",
        "        for eta in etas:\n",
        "            for lam in lambdas:\n",
        "                weights = optimize_weights(Sigma, mu, lam, gamma, eta, lr=1e-2, epochs=300, verbose=False)\n",
        "                sparsity = np.count_nonzero(weights)\n",
        "                final_obj = objective(weights, Sigma, mu, lam, gamma, eta)\n",
        "                penalty_val = kc_penalty(weights, gamma, eta)\n",
        "\n",
        "                # Append to master log\n",
        "                master_log += \"==== Kolmogorov Complexity Stress Test ====\\n\"\n",
        "                master_log += f\"Number of assets: {n_assets}\\n\"\n",
        "                master_log += f\"Gamma (L0 penalty): {gamma}\\n\"\n",
        "                master_log += f\"Eta (L1 penalty): {eta}\\n\"\n",
        "                master_log += f\"Lambda (risk-return trade-off): {lam}\\n\\n\"\n",
        "                master_log += f\"Final weights: {weights.tolist()}\\n\"\n",
        "                master_log += f\"Sparsity (non-zero): {sparsity}\\n\"\n",
        "                master_log += f\"Final objective value: {final_obj:.6f}\\n\"\n",
        "                master_log += f\"Penalty value: {penalty_val:.6f}\\n\"\n",
        "                master_log += \"===========================================\\n\\n\"\n",
        "\n",
        "# Save master log to single file\n",
        "with open(\"kc_test_master_log.txt\", \"w\") as f:\n",
        "    f.write(master_log)\n",
        "\n",
        "print(\"✅ All large-scale stress tests completed.\")\n",
        "print(\"✅ Master log saved to kc_test_master_log.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cakID9hvLwcT",
        "outputId": "2162d2e1-616e-466b-f89f-a1e37eb3a1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All large-scale stress tests completed.\n",
            "✅ Master log saved to kc_test_master_log.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def kc_penalty(w, gamma=1e-2, eta=1e-2):\n",
        "    return gamma * np.count_nonzero(w) + eta * np.sum(np.abs(w))\n",
        "\n",
        "def objective(w, Sigma, mu, lam, gamma, eta):\n",
        "    risk = w.T @ Sigma @ w\n",
        "    ret = w.T @ mu\n",
        "    return risk - lam * ret + kc_penalty(w, gamma, eta)\n",
        "\n",
        "def grad_objective(w, Sigma, mu, lam, eta):\n",
        "    return 2 * Sigma @ w - lam * mu + eta * np.sign(w)\n",
        "\n",
        "def optimize_weights(Sigma, mu, lam, gamma, eta, lr=1e-2, epochs=300):\n",
        "    w = np.ones_like(mu) / len(mu)\n",
        "    for _ in range(epochs):\n",
        "        grad = grad_objective(w, Sigma, mu, lam, eta)\n",
        "        w -= lr * grad\n",
        "        w[np.abs(w) < gamma] = 0\n",
        "        w = np.maximum(w, 0)\n",
        "        if np.sum(w) > 0:\n",
        "            w /= np.sum(w)\n",
        "    return w\n",
        "\n",
        "# Base setup\n",
        "np.random.seed(42)\n",
        "n_assets = 20\n",
        "Sigma = np.random.rand(n_assets, n_assets)\n",
        "Sigma = Sigma @ Sigma.T + 1e-3 * np.eye(n_assets)\n",
        "mu = np.random.rand(n_assets)\n",
        "\n",
        "# Original\n",
        "w_base = optimize_weights(Sigma, mu, lam=1.0, gamma=0.01, eta=0.01)\n",
        "\n",
        "# Perturbations\n",
        "epsilon = 1e-3\n",
        "Sigma_pert = Sigma + epsilon * np.random.randn(n_assets, n_assets)\n",
        "Sigma_pert = Sigma_pert @ Sigma_pert.T + 1e-3 * np.eye(n_assets)\n",
        "mu_pert = mu + epsilon * np.random.randn(n_assets)\n",
        "\n",
        "w_pert = optimize_weights(Sigma_pert, mu_pert, lam=1.0, gamma=0.01, eta=0.01)\n",
        "\n",
        "print(\"Original weights:\", w_base)\n",
        "print(\"Perturbed weights:\", w_pert)\n",
        "print(\"Difference (L2 norm):\", np.linalg.norm(w_base - w_pert))\n"
      ],
      "metadata": {
        "id": "iEm4DNgrMS0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fedc3f4-3f27-435c-aa06-33d58957bcfa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Perturbed weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Difference (L2 norm): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse functions above\n",
        "\n",
        "np.random.seed(42)\n",
        "n_assets = 20\n",
        "Sigma = np.random.rand(n_assets, n_assets)\n",
        "Sigma = Sigma @ Sigma.T + 1e-3 * np.eye(n_assets)\n",
        "mu = np.random.rand(n_assets)\n",
        "\n",
        "# Extremely high penalties\n",
        "gamma_high = 5.0\n",
        "eta_high = 5.0\n",
        "\n",
        "w_collapse = optimize_weights(Sigma, mu, lam=1.0, gamma=gamma_high, eta=eta_high)\n",
        "\n",
        "print(\"Extreme penalty weights:\", w_collapse)\n",
        "print(\"Sparsity (non-zero count):\", np.count_nonzero(w_collapse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hd7WxNWM87I",
        "outputId": "91ededf9-3155-4995-816d-a5ba9b22e4ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extreme penalty weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Sparsity (non-zero count): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse functions above\n",
        "\n",
        "np.random.seed(42)\n",
        "n_assets = 20\n",
        "Sigma = np.random.rand(n_assets, n_assets)\n",
        "Sigma = Sigma @ Sigma.T + 1e-3 * np.eye(n_assets)\n",
        "mu = np.random.rand(n_assets)\n",
        "\n",
        "results = []\n",
        "\n",
        "for trial in range(5):\n",
        "    # Random initialization instead of uniform\n",
        "    w_init = np.random.rand(n_assets)\n",
        "    w_init /= np.sum(w_init)\n",
        "\n",
        "    def optimize_from_custom(w_start):\n",
        "        w = w_start.copy()\n",
        "        for _ in range(300):\n",
        "            grad = grad_objective(w, Sigma, mu, lam=1.0, eta=0.01)\n",
        "            w -= 1e-2 * grad\n",
        "            w[np.abs(w) < 0.01] = 0\n",
        "            w = np.maximum(w, 0)\n",
        "            if np.sum(w) > 0:\n",
        "                w /= np.sum(w)\n",
        "        return w\n",
        "\n",
        "    w_result = optimize_from_custom(w_init)\n",
        "    results.append(w_result)\n",
        "    print(f\"Trial {trial + 1} final weights:\", w_result)\n",
        "    print(\"Sparsity:\", np.count_nonzero(w_result))\n",
        "    print(\"=====\")\n",
        "\n",
        "# Compare if solutions converge to same sparse pattern\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcVgQh4UM-Jh",
        "outputId": "e28aa98b-eca3-4966-d2a0-a855172b0736"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 final weights: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Sparsity: 1\n",
            "=====\n",
            "Trial 2 final weights: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Sparsity: 1\n",
            "=====\n",
            "Trial 3 final weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Sparsity: 0\n",
            "=====\n",
            "Trial 4 final weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Sparsity: 0\n",
            "=====\n",
            "Trial 5 final weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Sparsity: 0\n",
            "=====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rdnxgenUM_Wc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}